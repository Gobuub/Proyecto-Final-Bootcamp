{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5efefb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelos.modelos import comunio_pred_lib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from lightgbm import LGBMRegressor as LGBR\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('display.max_rows',None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d2b77e",
   "metadata": {},
   "source": [
    "## Primero obtenemos los datos para entrenar los modelos\n",
    "\n",
    "    Para ello utilizo las funciones en el archivo comunio_pred_lib.\n",
    "    - create_data_train genera un data frame por cada jornada que reciba como argumento\n",
    "    - preprocess_data recibe el data frame resultante de la operación de antes y nos genera\n",
    "      las variables necesarias para entrenar nuestros modelos.\n",
    "          - X: Datos numéricos de nuestro data frame inicial sin el target\n",
    "          - y: Target que recibirá nuestro modelo\n",
    "          - X_train, X_test, y_train, y_test : Datos resultantes de realizar la operación train_test_split\n",
    "          - X_train_s, X_test_s, y_train_s, y_test_s: Datos anteriores normalizados\n",
    "          - x_scaler, y_scaler: Variable necesaria para poder transformar los datos en el futuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634a5b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of journeys to create a full data frame to train de models\n",
    "\n",
    "j = [19,20,21,23,25,26,27,28,29,30,31,32]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for journey in j:\n",
    "    print('Añadiendo Jornada',journey)\n",
    "    if journey != 21 and journey != 23:\n",
    "        \n",
    "        df_2 = comunio_pred_lib.create_data_train(journey)\n",
    "\n",
    "        n_j = journey+1\n",
    "        \n",
    "        next_j = comunio_pred_lib.create_data_train(n_j)\n",
    "        next_j = next_j[['Player','J_Actual']]\n",
    "        next_j_target= next_j.rename(columns={'Player': 'Jugador', 'J_Actual':'Target'})\n",
    "        df_3 = df_2.merge(next_j_target, how='left', left_on='Player', right_on='Jugador')\n",
    "        df_3 = df_3.dropna()\n",
    "            \n",
    "        \n",
    "    \n",
    "    else:\n",
    "        \n",
    "        df_2 = comunio_pred_lib.create_data_train(journey)\n",
    "        n_j = journey+2\n",
    "        \n",
    "        next_j = comunio_pred_lib.create_data_train(n_j)\n",
    "        next_j = next_j[['Player','J_1']]\n",
    "        next_j_target= next_j.rename(columns={'Player': 'Jugador', 'J_1':'Target'})\n",
    "        df_3 = df_2.merge(next_j_target, how='left', left_on='Player', right_on='Jugador')\n",
    "        df_3 = df_3.dropna()\n",
    "\n",
    "    df = df.append(df_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f07b814",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, X_train, X_test, y_train, y_test ,X_train_s, X_test_s, y_train_s, y_test_s, x_scaler, y_scaler = comunio_pred_lib.preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7e2ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(max_depth= 5, max_leaf_nodes= 35, n_estimators= 300, n_jobs= -1)\n",
    "xgbr = XGBRegressor(max_depth=5, n_estimators=500,learning_rate=0.01, n_jobs=-1, gamma=0.1 )\n",
    "gb = GradientBoostingRegressor(max_depth=5, n_estimators=400,learning_rate=0.001, alpha=0.8, max_leaf_nodes=35)\n",
    "models = (rfr,xgbr,gb)\n",
    "for model in models:\n",
    "    name = str(model)[:13]\n",
    "  \n",
    "    model.fit(X_train_s,y_train)\n",
    "    model.score(X_train_s, y_train)\n",
    "    pred = model.predict(X_test_s)\n",
    "    mse = mean_squared_error(pred,y_test, squared=False)\n",
    "    \n",
    "    \n",
    "    print (f'mse del modelo {name} = {mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa253c41",
   "metadata": {},
   "source": [
    "### Reentrenamos los modelos ahora con todos los datos para predecir jornadas venideras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cb7f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr.fit(X,y)\n",
    "xgbr.fit(X,y)\n",
    "gb.fit(X,y)\n",
    "'Modelos entrenados'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc2b3ee",
   "metadata": {},
   "source": [
    "### Se entrenaron dos modelos de redes neuronales con los mismos parámetros salvo las épocas.\n",
    "    Ejemplo de uno de ellos.\n",
    "    Se entreno con 10 y 20 epocas\n",
    "    rnn con 20 epocas y rnn2 con 10 epocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f4f857",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn =  Sequential()\n",
    "\n",
    "rnn.add(Dense(500, activation='relu',input_dim=27))\n",
    "rnn.add(Dense(250, activation='relu'))\n",
    "rnn.add(Dense(125, activation='relu'))\n",
    "rnn.add(Dense(60, activation='relu'))\n",
    "rnn.add(Dense(1, activation='linear'))\n",
    "\n",
    "rnn.compile(loss=\"mean_squared_error\",\n",
    "             optimizer=\"adam\")\n",
    "his = rnn.fit(X_train_s,\n",
    "        y_train_s,\n",
    "        epochs=20,\n",
    "        validation_split=0.2\n",
    "        )\n",
    "pred_rnn = rnn.predict(X_test_s)\n",
    "pred2_rnn = y_scaler.inverse_transform(pred_rnn)\n",
    "mse = mean_squared_error(pred2_rnn,y_test, squared=False)\n",
    "\n",
    "        \n",
    "pd.DataFrame(his.history).plot(figsize=(8,5))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6290626",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f'mse del modelo rnn = {mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d830cd69",
   "metadata": {},
   "source": [
    "## Con los modelos ya entrenados realizamos las predicciones\n",
    "\n",
    "    Vamos utilizar los datos de la jornada 33 para predecir la jornada 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4a600e",
   "metadata": {},
   "outputs": [],
   "source": [
    "j_33 = comunio_pred_lib.create_data_train(33)\n",
    "j_34 = comunio_pred_lib.create_data_train(34)\n",
    "pred_data = j_33._get_numeric_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fb72be",
   "metadata": {},
   "outputs": [],
   "source": [
    "j_33.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec7c87e",
   "metadata": {},
   "source": [
    "### Realizamos las predicciones usando las funciones de nuestra librería\n",
    "\n",
    "    Todas las funciones son similares, reciben un dataframe y devuelven las prediciones de ese df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c971b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rfr = comunio_pred_lib.predict_rf(pred_data)\n",
    "pred_xgb = comunio_pred_lib.predict_xgb(pred_data)\n",
    "pred_gb = comunio_pred_lib.predict_gb(pred_data)\n",
    "pred_rnn = comunio_pred_lib.predict_rnn(pred_data)\n",
    "pred_rnn2 = comunio_pred_lib.predict_rnn2(pred_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b31caa",
   "metadata": {},
   "source": [
    "### Creamos un dataframe con las predicciones de nuestros modelos y añadimos la realidad para comparar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af20d38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.DataFrame(j_33['Player'])\n",
    "preds['Position'] = j_33.Position\n",
    "preds['rfr'] = pred_rfr\n",
    "preds['xgb'] = pred_xgb\n",
    "preds['gb'] = pred_gb\n",
    "preds['rnn'] = pred_rnn\n",
    "preds['rnn2'] = pred_rnn2\n",
    "preds = preds.merge(j_34[['Player','J_Actual']], left_on='Player', right_on='Player')\n",
    "preds = round(preds)\n",
    "preds['avg_l_5_J'] = j_33.Avg_last_5_games\n",
    "\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c67d36f",
   "metadata": {},
   "source": [
    "### Ahora vamos a explorar un poco los resultados y obtener los 11 ideales para la J 34\n",
    "\n",
    "    Para utilizamos las funciones de once_ideal_(modelo) para obtener el once ideal previsto por ese modelo.\n",
    "    Disponemos de 5 funciones:            \n",
    "    \n",
    "    Cada función recibe unos datos y la disposición de la alineación, numero de defensas, medios atacantes.\n",
    "    \n",
    "        - once_ideal_rf (Usa el modelo random forest)\n",
    "        - once_ideal_xgb (Usa el modelo xgboot)\n",
    "        - once_ideal_gb (Usa el modelo gradient boost)\n",
    "        - once_ideal_rnn (Usa el modelo red neuronal con 20 épocas)\n",
    "        - once_ideal_rnn2 (Usa el modelo red neuronal con 10 épocas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66853cd0",
   "metadata": {},
   "source": [
    "### Distribución de los puntos de todos los jugadores en la J 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b8ae52",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(j_34['J_Actual'], bins=10);\n",
    "plt.title('Distribución puntos Jornada 34')\n",
    "plt.xlabel('Ptos el jugador');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43fbac0",
   "metadata": {},
   "source": [
    "#### Distribución de las predicciones de cada uno de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45189551",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(round(preds.rfr), bins=8);\n",
    "plt.title('Distribución predicciones Random Forest')\n",
    "plt.xlabel('Predicción ptos el jugador');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23163ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(round(preds.xgb), bins=8);\n",
    "plt.title('Distribución predicciones XGBoost')\n",
    "plt.xlabel('Predicción ptos el jugador');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a8514b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(round(preds.gb), bins=8);\n",
    "plt.title('Distribución predicciones Gradient Boost')\n",
    "plt.xlabel('Predicción ptos el jugador');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323ac02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(round(preds.rnn), bins=8);\n",
    "plt.title('Distribución predicciones Red Neuronal')\n",
    "plt.xlabel('Predicción ptos el jugador');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74d4e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(round(preds.rnn2), bins=8);\n",
    "plt.title('Distribución predicciones Red Neuronal 2')\n",
    "plt.xlabel('Predicción ptos el jugador');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bceed946",
   "metadata": {},
   "source": [
    "### Generamos los onces ideales de cada equipo y comparamos la predicción con los datos reales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b5b9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eleven_rf = comunio_pred_lib.once_ideal_rf(preds,3,4,3)\n",
    "eleven_xgb = comunio_pred_lib.once_ideal_xbgr(preds,3,4,3)\n",
    "eleven_gb = comunio_pred_lib.once_ideal_gb(preds,3,4,3)\n",
    "eleven_rnn = comunio_pred_lib.once_ideal_rnn(preds,3,4,3)\n",
    "eleven_rnn2 = comunio_pred_lib.once_ideal_rnn2(preds,3,4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb95a808",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Totales xgb: ', sum(eleven_xgb.xgb), ', real: ', \n",
    "      sum(eleven_xgb.J_Actual)\n",
    "     )\n",
    "print('Totales rfr: ', sum(eleven_rf.rfr), ', real: ', \n",
    "      sum(eleven_rf.J_Actual)\n",
    "     )\n",
    "print('Totales gb: ', sum(eleven_gb.gb), ', real: ', \n",
    "      sum(eleven_gb.J_Actual)\n",
    "     )\n",
    "print('Totales rnn: ', sum(eleven_rnn.rnn), ', real: ', \n",
    "      sum(eleven_rnn.J_Actual)\n",
    "     )\n",
    "print('Totales rnn2: ', sum(eleven_rnn2.rnn2), ', real: ', \n",
    "      sum(eleven_rnn2.J_Actual)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63d1eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "eleven_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee2f668",
   "metadata": {},
   "outputs": [],
   "source": [
    "eleven_rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e17e02",
   "metadata": {},
   "source": [
    "### Ahora vamos a testear con una plantilla real la mía del comunio a ver que alineación recomienda\n",
    "\n",
    "    Primero generamos un df a partir de los datos de prediciones que tenemos, y los filtramos con los jugadores que tengo en mi plantilla de comunio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e2cbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "squad = ['Courtois', 'Bono',\n",
    "         'Balliu', \n",
    "         'Fran García',\n",
    "         'Maffeo',\n",
    "         'Ronald Araujo', \n",
    "         'Alderete', 'Manu Sánchez', \n",
    "         #'Giménez', Está lesionado o tenía pocas posibilidades de jugar\n",
    "         #'Yéremi',  \n",
    "         'Gavi',  \n",
    "         #'Modric',  \n",
    "         'Brais', 'Papu Gómez', 'Dani Rodríguez', 'Pere Milla', 'Cervi', 'Berenguer',\n",
    "         'Vinícius Júnior', 'Aubameyang', \n",
    "         #'Sancet',  \n",
    "         'Morales']\n",
    "df_squad_kike = pd.DataFrame()\n",
    "for player in squad:\n",
    "    #print (player)\n",
    "    for p in preds.Player:\n",
    "        if player in p:\n",
    "            #print('encontrado')\n",
    "            add_player = pd.DataFrame(preds.loc[preds.Player==p])\n",
    "            #print(add_player)\n",
    "            df_squad_kike = df_squad_kike.append(add_player)\n",
    "print(len(squad),len(df_squad_kike))\n",
    "\n",
    "df_squad_kike.at[520,'Position'] = 'MD'\n",
    "df_squad_kike = round(df_squad_kike)\n",
    "df_squad_kike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39461ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_eleven_kike = round(comunio_pred_lib.once_ideal_xbgr(df_squad_kike,3,5,2))\n",
    "\n",
    "rf_eleven_kike = round(comunio_pred_lib.once_ideal_rf(df_squad_kike,3,5,2))\n",
    "\n",
    "gb_eleven_kike = round(comunio_pred_lib.once_ideal_gb(df_squad_kike,3,5,2))\n",
    "\n",
    "rnn_eleven_kike = round(comunio_pred_lib.once_ideal_rnn(df_squad_kike,3,5,2))\n",
    "\n",
    "rnn2_eleven_kike = round(comunio_pred_lib.once_ideal_rnn2(df_squad_kike,3,5,2))\n",
    "\n",
    "print('Totales xgb: ', sum(xgb_eleven_kike.xgb), ', real: ', \n",
    "      sum(xgb_eleven_kike.J_Actual)\n",
    "     )\n",
    "print('Totales rfr: ', sum(rf_eleven_kike.rfr), ', real: ', \n",
    "      sum(rf_eleven_kike.J_Actual)\n",
    "     )\n",
    "print('Totales gb: ', sum(gb_eleven_kike.gb), ', real: ', \n",
    "      sum(gb_eleven_kike.J_Actual)\n",
    "     )\n",
    "print('Totales rnn: ', sum(rnn_eleven_kike.rnn), ', real: ', \n",
    "      sum(rnn_eleven_kike.J_Actual)\n",
    "     )\n",
    "print('Totales rnn2: ', sum(rnn2_eleven_kike.rnn2), ', real: ', \n",
    "      sum(rnn2_eleven_kike.J_Actual)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b4f2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_eleven_kike\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1f2302",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn2_eleven_kike"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4144fd1",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "El peor modelo es sin duda el gradient boost, ya que prácticamente asigna la misma puntución a todos los jugadores.\n",
    "El resto de modelos funcionan bastante bien y aunque el rnn2 no es el que mejores resultados obtiene en cuanto error absoluto es el que mejor generaliza y se acerca más a la realidad, solo hay que comparar las distribuciones de la puntuación real y de la rnn2 para ver que son las más similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55de58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df_squad_kike.rnn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92f7dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
